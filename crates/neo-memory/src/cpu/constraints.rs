//! CPU constraint builder for Neo.
//!
//! This module provides R1CS/CCS constraints that bind CPU semantics to the shared
//! memory/lookup bus. These constraints are **critical for security** - without them,
//! a malicious prover can create divergent CPU and memory states.
//!
//! # Credits
//!
//! The constraint logic in this module is ported from the Jolt zkVM project:
//! - Repository: https://github.com/a16z/jolt
//! - Original file: `jolt-core/src/zkvm/r1cs/constraints.rs`
//! - License: Apache-2.0 / MIT
//!
//! Jolt's R1CS constraint system defines the binding between CPU instruction semantics
//! and memory/lookup values. We adapt this for Neo's CCS-based proving system and
//! shared CPU bus architecture.
//!
//! # Architecture
//!
//! Neo's shared CPU bus places memory/lookup columns in the tail of the CPU witness:
//!
//! ```text
//! z = [x | w_cpu | ... | bus_tail ]
//!      └─┬─┘     └──────┬────────┘
//!     public       private witness
//!
//! bus_tail layout (per step):
//!   - Shout instances: [addr_bits..., has_lookup, val]
//!   - Twist instances: [ra_bits..., wa_bits..., has_read, has_write, wv, rv, inc]
//! ```
//!
//! The constraints in this module enforce that CPU semantic columns (e.g., the value
//! a load instruction writes to a register) are equal to the corresponding bus columns
//! (e.g., `rv` from Twist).

use core::ops::Range;
use neo_ccs::matrix::Mat;
use neo_ccs::poly::{SparsePoly, Term};
use neo_ccs::relations::CcsStructure;
use neo_ccs::{CcsMatrix, CscMat};
use p3_field::{Field, PrimeCharacteristicRing};

use crate::cpu::bus_layout::{
    build_bus_layout_for_instances_with_shout_shapes_and_twist_lanes, BusLayout, ShoutCols, ShoutInstanceShape,
    TwistCols,
};
use crate::riscv::trace::{rv32_trace_lookup_addr_group_for_table_shape, rv32_trace_lookup_selector_group_for_table_id};
use crate::witness::{LutInstance, MemInstance};

/// CPU column layout for binding to the bus.
///
/// This mirrors Jolt's `JoltR1CSInputs` but is specific to Neo's witness structure.
///
/// # Credits
/// Adapted from Jolt's `JoltR1CSInputs` enum in `jolt-core/src/zkvm/r1cs/inputs.rs`.
#[derive(Clone, Debug)]
pub struct CpuColumnLayout {
    /// Column index of the CPU's "is_load" selector (1 when executing a load instruction).
    pub is_load: usize,
    /// Column index of the CPU's "is_store" selector (1 when executing a store instruction).
    pub is_store: usize,
    /// Column index of the CPU's effective address (rs1 + imm for RISC-V).
    pub effective_addr: usize,
    /// Column index of the CPU's destination register write value (for loads).
    pub rd_write_value: usize,
    /// Column index of the CPU's source register value (for stores, typically rs2).
    pub rs2_value: usize,
    /// Column index for the CPU's lookup selector (1 when executing a lookup).
    pub is_lookup: usize,
    /// Column index for the CPU's lookup key (the table index / operand).
    pub lookup_key: usize,
    /// Column index for the CPU's lookup output value.
    pub lookup_output: usize,
}

/// Per-instance CPU→bus binding for a Twist (memory) bus slice.
///
/// This is intentionally generic: the CPU may have multiple memory units/ports, so each Twist
/// instance must bind to its own selector/address/value columns.
#[derive(Clone, Debug)]
pub struct TwistCpuBinding {
    /// CPU selector column for a read op (must equal bus `has_read`).
    pub has_read: usize,
    /// CPU selector column for a write op (must equal bus `has_write`).
    pub has_write: usize,

    /// Packed integer read address column (must equal packed bus `ra_bits` when `has_read=1`).
    pub read_addr: usize,
    /// Packed integer write address column (must equal packed bus `wa_bits` when `has_write=1`).
    pub write_addr: usize,

    /// CPU read value column (must equal bus `rv` when `has_read=1`).
    pub rv: usize,
    /// CPU write value column (must equal bus `wv` when `has_write=1`).
    pub wv: usize,

    /// Optional CPU-side increment column (must equal bus `inc_at_write_addr` when `has_write=1`).
    pub inc: Option<usize>,
}

/// Sentinel column id used to disable a Twist CPU linkage field on a lane.
///
/// This is only valid for `TwistCpuBinding` fields and is interpreted by the constraint builder
/// as "no CPU binding for this selector/value/address family". In that mode the lane is still
/// protected by canonical bus padding/bitness constraints.
pub const CPU_BUS_COL_DISABLED: usize = usize::MAX;

/// Per-instance CPU→bus binding for a Shout (lookup) bus slice.
#[derive(Clone, Debug)]
pub struct ShoutCpuBinding {
    /// CPU selector column for a lookup op (must equal bus `has_lookup`).
    ///
    /// `CPU_BUS_COL_DISABLED` disables selector/value linkage for this lane while still allowing
    /// optional key binding through `addr` (conditioned by bus `has_lookup`).
    pub has_lookup: usize,
    /// Optional packed integer lookup key/address column.
    ///
    /// When set, shared-bus constraints bind this scalar to the bus `addr_bits` via bit-packing
    /// (when `has_lookup=1`).
    ///
    /// Some circuits avoid packing large keys into a single field element (e.g. 64-bit interleaved
    /// RISC-V Shout keys) and instead constrain the bus `addr_bits` directly. Those circuits should
    /// set this to `None`.
    pub addr: Option<usize>,
    /// CPU lookup output/value column (must equal bus `val` when `has_lookup=1`).
    ///
    /// `CPU_BUS_COL_DISABLED` disables value linkage for this lane.
    pub val: usize,
}

/// Constraint label for debugging and logging.
///
/// # Credits
/// Adapted from Jolt's `R1CSConstraintLabel` in `jolt-core/src/zkvm/r1cs/constraints.rs`.
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]
pub enum CpuConstraintLabel {
    /// Load: RamReadValue == RdWriteValue (when Load flag is set)
    LoadValueBinding,
    /// Store: Rs2Value == RamWriteValue (when Store flag is set)
    StoreValueBinding,
    /// Load: Packed bus `ra_bits` matches CPU effective address.
    LoadAddressBinding,
    /// Store: Packed bus `wa_bits` matches CPU effective address.
    StoreAddressBinding,
    /// Padding: rv == 0 (when NOT has_read)
    ReadValueZeroPadding,
    /// Padding: wv == 0 (when NOT has_write)
    WriteValueZeroPadding,
    /// Padding: ra_bits == 0 (when NOT has_read)
    ReadAddressBitsZeroPadding,
    /// Padding: wa_bits == 0 (when NOT has_write)
    WriteAddressBitsZeroPadding,
    /// Bitness: has_read is boolean (0/1).
    TwistHasReadBoolean,
    /// Bitness: has_write is boolean (0/1).
    TwistHasWriteBoolean,
    /// Bitness: each read address bit is 0 when inactive, boolean when active.
    TwistReadAddrBitBitness,
    /// Bitness: each write address bit is 0 when inactive, boolean when active.
    TwistWriteAddrBitBitness,
    /// Padding: inc_at_write_addr == 0 (when NOT has_write)
    IncrementZeroPadding,
    /// Write: cpu_inc == bus_inc (when has_write)
    IncrementBinding,
    /// Lookup: val == lookup_output (when has_lookup)
    LookupValueBinding,
    /// Lookup: packed bus `addr_bits` matches CPU lookup key.
    LookupKeyBinding,
    /// Padding: lookup val == 0 (when NOT has_lookup)
    LookupValueZeroPadding,
    /// Padding: lookup addr_bits == 0 (when NOT has_lookup)
    LookupAddressBitsZeroPadding,
    /// Bitness: has_lookup is boolean (0/1).
    ShoutHasLookupBoolean,
    /// Bitness: each lookup key bit is 0 when inactive, boolean when active.
    ShoutAddrBitBitness,
    /// Selector binding: is_load == has_read
    LoadSelectorBinding,
    /// Selector binding: is_store == has_write
    StoreSelectorBinding,
    /// Selector binding: is_lookup == has_lookup
    LookupSelectorBinding,

    /// Multi-read-port helper: mirror Twist write stream across multiple Twist instances.
    ///
    /// These are unconditional equalities between **bus** columns of different Twist instances,
    /// used to emulate multiple read ports against a single logical memory by replicating the
    /// Twist instance and forcing all replicas to share the same write stream.
    TwistWriteMirrorHasWrite,
    TwistWriteMirrorWaBits,
    TwistWriteMirrorWv,
    TwistWriteMirrorInc,
}

/// A single constraint in the CPU binding system.
///
/// Represents: `condition * (left - right) = 0`
///
/// # Credits
/// Adapted from Jolt's `R1CSConstraint` and `r1cs_eq_conditional!` macro.
#[derive(Clone, Debug)]
pub struct CpuConstraint<F> {
    /// Human-readable label for debugging.
    pub label: CpuConstraintLabel,
    /// Condition column index (selector).
    pub condition_col: usize,
    /// Whether to negate the condition (1 - condition).
    pub negate_condition: bool,
    /// Optional: additional columns to add to the condition (for OR-style conditions).
    pub additional_condition_cols: Vec<usize>,
    /// Linear expression for the B side: Σ coeffᵢ · z[colᵢ].
    ///
    /// The constraint enforced is:
    ///   A(z) * B(z) = 0
    /// where A(z) is the (possibly negated / OR'ed) condition expression.
    pub b_terms: Vec<(usize, F)>,
}

impl<F: Field> CpuConstraint<F> {
    /// Create a constraint: `condition * (left - right) = 0`.
    pub fn new_eq(label: CpuConstraintLabel, condition_col: usize, left_col: usize, right_col: usize) -> Self {
        Self {
            label,
            condition_col,
            negate_condition: false,
            additional_condition_cols: Vec::new(),
            b_terms: vec![(left_col, F::ONE), (right_col, -F::ONE)],
        }
    }

    /// Create a constraint: `(1 - condition) * (left - right) = 0`.
    pub fn new_eq_negated(label: CpuConstraintLabel, condition_col: usize, left_col: usize, right_col: usize) -> Self {
        Self {
            label,
            condition_col,
            negate_condition: true,
            additional_condition_cols: Vec::new(),
            b_terms: vec![(left_col, F::ONE), (right_col, -F::ONE)],
        }
    }

    /// Create a constraint with OR condition: `(cond1 + cond2 + ...) * (left - right) = 0`.
    pub fn new_with_or_eq(
        label: CpuConstraintLabel,
        condition_cols: &[usize],
        left_col: usize,
        right_col: usize,
    ) -> Self {
        assert!(!condition_cols.is_empty(), "need at least one condition");
        Self {
            label,
            condition_col: condition_cols[0],
            negate_condition: false,
            additional_condition_cols: condition_cols[1..].to_vec(),
            b_terms: vec![(left_col, F::ONE), (right_col, -F::ONE)],
        }
    }

    /// Create a constraint: `condition * (col) = 0`.
    pub fn new_zero(label: CpuConstraintLabel, condition_col: usize, col: usize) -> Self {
        Self {
            label,
            condition_col,
            negate_condition: false,
            additional_condition_cols: Vec::new(),
            b_terms: vec![(col, F::ONE)],
        }
    }

    /// Create a constraint: `(1 - condition) * (col) = 0`.
    pub fn new_zero_negated(label: CpuConstraintLabel, condition_col: usize, col: usize) -> Self {
        Self {
            label,
            condition_col,
            negate_condition: true,
            additional_condition_cols: Vec::new(),
            b_terms: vec![(col, F::ONE)],
        }
    }

    /// Create a constraint with an arbitrary B-side linear expression:
    /// `condition * (Σ coeffᵢ · z[colᵢ]) = 0`.
    pub fn new_terms(
        label: CpuConstraintLabel,
        condition_col: usize,
        negate_condition: bool,
        b_terms: Vec<(usize, F)>,
    ) -> Self {
        Self {
            label,
            condition_col,
            negate_condition,
            additional_condition_cols: Vec::new(),
            b_terms,
        }
    }
}

/// Builder for CPU-to-bus binding constraints.
///
/// Generates CCS constraints that enforce the binding between CPU semantics
/// and the shared memory/lookup bus.
///
/// # Credits
/// The constraint logic is adapted from Jolt's `R1CS_CONSTRAINTS` static array
/// in `jolt-core/src/zkvm/r1cs/constraints.rs`.
///
/// # Example
/// ```ignore
/// let mut builder = CpuConstraintBuilder::new(n, m, bus_base, const_one_col);
/// builder.add_twist_instance(twist_cfg, cpu_layout);
/// builder.add_shout_instance(shout_cfg, cpu_layout);
/// let ccs = builder.build()?;
/// ```
#[derive(Clone, Debug)]
pub struct CpuConstraintBuilder<F: Field> {
    /// Number of constraint rows.
    pub n: usize,
    /// Number of witness columns.
    pub m: usize,
    /// Column index that must be fixed to 1 (typically the R1CS constant-one column).
    pub const_one_col: usize,
    /// Accumulated constraints.
    constraints: Vec<CpuConstraint<F>>,
}

impl<F: Field> CpuConstraintBuilder<F> {
    /// Create a new constraint builder.
    ///
    /// # Arguments
    /// * `n` - Number of constraint rows
    /// * `m` - Number of witness columns (including bus tail)
    /// * `const_one_col` - Column index that is fixed to 1 (public or otherwise constrained)
    pub fn new(n: usize, m: usize, const_one_col: usize) -> Self {
        Self {
            n,
            m,
            const_one_col,
            constraints: Vec::new(),
        }
    }

    fn add_boolean_constraint(&mut self, label: CpuConstraintLabel, col: usize) {
        self.constraints.push(CpuConstraint::new_terms(
            label,
            col,
            false,
            vec![(col, F::ONE), (self.const_one_col, -F::ONE)],
        ));
    }

    fn add_gated_bit_constraint(&mut self, label: CpuConstraintLabel, bit_col: usize, enable_col: usize) {
        self.constraints.push(CpuConstraint::new_terms(
            label,
            bit_col,
            false,
            vec![(bit_col, F::ONE), (enable_col, -F::ONE)],
        ));
    }

    /// Add constraints for a Twist (memory) instance.
    ///
    /// # Constraints Added (from Jolt)
    ///
    /// **Value Binding:**
    /// - `is_load * (bus_rv - rd_write_value) = 0` (Load: memory value → register)
    /// - `is_store * (bus_wv - rs2_value) = 0` (Store: register value → memory)
    ///
    /// **Selector Binding:**
    /// - `is_load - has_read = 0` (CPU load flag must match bus has_read)
    /// - `is_store - has_write = 0` (CPU store flag must match bus has_write)
    ///
    /// **Padding Constraints:**
    /// - `(1 - has_read) * rv = 0`
    /// - `(1 - has_write) * wv = 0`
    /// - `(1 - has_read) * ra_bits[i] = 0` for all i
    /// - `(1 - has_write) * wa_bits[i] = 0` for all i
    /// - `(1 - has_write) * inc_at_write_addr = 0`
    ///
    /// # Credits
    /// Constraints adapted from:
    /// - `RamReadEqRdWriteIfLoad` in Jolt
    /// - `Rs2EqRamWriteIfStore` in Jolt
    /// - `RamAddrEqZeroIfNotLoadStore` in Jolt
    pub fn add_twist_instance(&mut self, layout: &BusLayout, twist: &TwistCols, cpu_layout: &CpuColumnLayout) {
        let cpu = TwistCpuBinding {
            has_read: cpu_layout.is_load,
            has_write: cpu_layout.is_store,
            read_addr: cpu_layout.effective_addr,
            write_addr: cpu_layout.effective_addr,
            rv: cpu_layout.rd_write_value,
            wv: cpu_layout.rs2_value,
            inc: None,
        };
        self.add_twist_instance_bound(layout, twist, &cpu);
    }

    /// Add constraints for a Twist (memory) instance using an explicit per-instance CPU binding.
    pub fn add_twist_instance_bound(&mut self, layout: &BusLayout, twist: &TwistCols, cpu: &TwistCpuBinding) {
        for j in 0..layout.chunk_size {
            // Bus column indices (absolute in witness)
            let bus_has_read = layout.bus_cell(twist.has_read, j);
            let bus_has_write = layout.bus_cell(twist.has_write, j);
            let bus_rv = layout.bus_cell(twist.rv, j);
            let bus_wv = layout.bus_cell(twist.wv, j);
            let bus_inc = layout.bus_cell(twist.inc, j);

            // CPU columns are assumed to be chunked (contiguous, per-step): col(j) = col_base + j.
            let cpu_has_read = (cpu.has_read != CPU_BUS_COL_DISABLED).then_some(cpu.has_read + j);
            let cpu_has_write = (cpu.has_write != CPU_BUS_COL_DISABLED).then_some(cpu.has_write + j);
            let cpu_read_addr = (cpu.read_addr != CPU_BUS_COL_DISABLED).then_some(cpu.read_addr + j);
            let cpu_write_addr = (cpu.write_addr != CPU_BUS_COL_DISABLED).then_some(cpu.write_addr + j);
            let cpu_rv = (cpu.rv != CPU_BUS_COL_DISABLED).then_some(cpu.rv + j);
            let cpu_wv = (cpu.wv != CPU_BUS_COL_DISABLED).then_some(cpu.wv + j);
            let cpu_inc = cpu
                .inc
                .and_then(|col| (col != CPU_BUS_COL_DISABLED).then_some(col + j));

            // Ensure bus selectors are boolean so gated-bit constraints imply true {0,1} bitness.
            self.add_boolean_constraint(CpuConstraintLabel::TwistHasReadBoolean, bus_has_read);
            self.add_boolean_constraint(CpuConstraintLabel::TwistHasWriteBoolean, bus_has_write);

            if let Some(cpu_has_read) = cpu_has_read {
                let cpu_rv = cpu_rv.expect("Twist read binding requires rv column");
                let cpu_read_addr = cpu_read_addr.expect("Twist read binding requires read_addr column");
                // has_read * (rv_cpu - bus_rv) = 0
                self.constraints.push(CpuConstraint::new_eq(
                    CpuConstraintLabel::LoadValueBinding,
                    cpu_has_read,
                    cpu_rv,
                    bus_rv,
                ));
                // Selector binding: cpu_has_read == bus_has_read
                self.add_equality_constraint(CpuConstraintLabel::LoadSelectorBinding, cpu_has_read, bus_has_read);
                // has_read * (read_addr - pack(ra_bits)) = 0
                self.constraints.push(CpuConstraint::new_terms(
                    CpuConstraintLabel::LoadAddressBinding,
                    cpu_has_read,
                    false,
                    pack_addr_bits::<F>(cpu_read_addr, twist.ra_bits.clone(), layout, j),
                ));
            } else {
                // Explicitly force the read selector to 0 when the lane is unbound.
                self.constraints.push(CpuConstraint::new_zero(
                    CpuConstraintLabel::LoadSelectorBinding,
                    self.const_one_col,
                    bus_has_read,
                ));
            }

            if let Some(cpu_has_write) = cpu_has_write {
                let cpu_wv = cpu_wv.expect("Twist write binding requires wv column");
                let cpu_write_addr = cpu_write_addr.expect("Twist write binding requires write_addr column");
                // has_write * (wv_cpu - bus_wv) = 0
                self.constraints.push(CpuConstraint::new_eq(
                    CpuConstraintLabel::StoreValueBinding,
                    cpu_has_write,
                    cpu_wv,
                    bus_wv,
                ));
                // Selector binding: cpu_has_write == bus_has_write
                self.add_equality_constraint(CpuConstraintLabel::StoreSelectorBinding, cpu_has_write, bus_has_write);
                // has_write * (write_addr - pack(wa_bits)) = 0
                self.constraints.push(CpuConstraint::new_terms(
                    CpuConstraintLabel::StoreAddressBinding,
                    cpu_has_write,
                    false,
                    pack_addr_bits::<F>(cpu_write_addr, twist.wa_bits.clone(), layout, j),
                ));
                // Optional: bind CPU increment semantics if provided.
                if let Some(cpu_inc) = cpu_inc {
                    self.constraints.push(CpuConstraint::new_eq(
                        CpuConstraintLabel::IncrementBinding,
                        cpu_has_write,
                        cpu_inc,
                        bus_inc,
                    ));
                }
            } else {
                // Explicitly force the write selector to 0 when the lane is unbound.
                self.constraints.push(CpuConstraint::new_zero(
                    CpuConstraintLabel::StoreSelectorBinding,
                    self.const_one_col,
                    bus_has_write,
                ));
            }

            // Padding: (1 - has_read) * rv = 0
            self.constraints.push(CpuConstraint::new_zero_negated(
                CpuConstraintLabel::ReadValueZeroPadding,
                bus_has_read,
                bus_rv,
            ));

            // Padding: (1 - has_write) * wv = 0
            self.constraints.push(CpuConstraint::new_zero_negated(
                CpuConstraintLabel::WriteValueZeroPadding,
                bus_has_write,
                bus_wv,
            ));

            // Padding: (1 - has_write) * inc_at_write_addr = 0
            self.constraints.push(CpuConstraint::new_zero_negated(
                CpuConstraintLabel::IncrementZeroPadding,
                bus_has_write,
                bus_inc,
            ));

            // Read address bits:
            // - Bitness: bit is 0 when inactive, boolean when active
            for col_id in twist.ra_bits.clone() {
                let bit = layout.bus_cell(col_id, j);
                self.add_gated_bit_constraint(CpuConstraintLabel::TwistReadAddrBitBitness, bit, bus_has_read);
            }

            // Write address bits:
            // - Bitness: bit is 0 when inactive, boolean when active
            for col_id in twist.wa_bits.clone() {
                let bit = layout.bus_cell(col_id, j);
                self.add_gated_bit_constraint(CpuConstraintLabel::TwistWriteAddrBitBitness, bit, bus_has_write);
            }
        }
    }

    /// Add constraints for a Shout (lookup) instance.
    ///
    /// # Constraints Added
    ///
    /// **Value Binding:**
    /// - `is_lookup * (lookup_output - bus_val) = 0`
    ///
    /// **Padding Constraints:**
    /// - `(1 - has_lookup) * val = 0`
    /// - `(1 - has_lookup) * addr_bits[i] = 0` for all i
    ///
    /// # Credits
    /// Constraints adapted from Jolt's `RdWriteEqLookupIfWriteLookupToRd`.
    pub fn add_shout_instance(&mut self, layout: &BusLayout, shout: &ShoutCols, cpu_layout: &CpuColumnLayout) {
        let cpu = ShoutCpuBinding {
            has_lookup: cpu_layout.is_lookup,
            addr: Some(cpu_layout.lookup_key),
            val: cpu_layout.lookup_output,
        };
        self.add_shout_instance_bound(layout, shout, &cpu);
    }

    /// Add constraints for a Shout (lookup) instance using an explicit per-instance CPU binding.
    pub fn add_shout_instance_bound(&mut self, layout: &BusLayout, shout: &ShoutCols, cpu: &ShoutCpuBinding) {
        self.add_shout_instance_linkage_bound(layout, shout, cpu);
        self.add_shout_instance_padding(layout, shout);
    }

    /// Add Shout CPU linkage constraints only (no selector bitness / inactive padding).
    pub fn add_shout_instance_linkage_bound(&mut self, layout: &BusLayout, shout: &ShoutCols, cpu: &ShoutCpuBinding) {
        for j in 0..layout.chunk_size {
            // Bus column indices
            let bus_has_lookup = layout.bus_cell(shout.has_lookup, j);
            let bus_val = layout.bus_cell(shout.primary_val(), j);

            // CPU columns are assumed to be chunked (contiguous, per-step): col(j) = col_base + j.
            let cpu_has_lookup = (cpu.has_lookup != CPU_BUS_COL_DISABLED).then_some(cpu.has_lookup + j);
            let cpu_val = (cpu.val != CPU_BUS_COL_DISABLED).then_some(cpu.val + j);

            if let (Some(cpu_has_lookup), Some(cpu_val)) = (cpu_has_lookup, cpu_val) {
                // Value binding: is_lookup * (lookup_output - bus_val) = 0
                self.constraints.push(CpuConstraint::new_eq(
                    CpuConstraintLabel::LookupValueBinding,
                    cpu_has_lookup,
                    cpu_val,
                    bus_val,
                ));

                // Selector binding: cpu_has_lookup == bus_has_lookup
                self.add_equality_constraint(
                    CpuConstraintLabel::LookupSelectorBinding,
                    cpu_has_lookup,
                    bus_has_lookup,
                );
            } else if cpu_has_lookup.is_some() || cpu_val.is_some() {
                debug_assert!(
                    false,
                    "ShoutCpuBinding must set both has_lookup and val, or disable both with CPU_BUS_COL_DISABLED"
                );
            }

            // Optional key binding (bit-pack): is_lookup * (lookup_key - pack(addr_bits)) = 0.
            //
            // If CPU selector linkage is disabled for this lane, use bus `has_lookup` as the gate.
            if let Some(cpu_addr_base) = cpu.addr {
                let cpu_addr = cpu_addr_base + j;
                let gate_col = cpu_has_lookup.unwrap_or(bus_has_lookup);
                self.constraints.push(CpuConstraint::new_terms(
                    CpuConstraintLabel::LookupKeyBinding,
                    gate_col,
                    false,
                    pack_addr_bits::<F>(cpu_addr, shout.addr_bits.clone(), layout, j),
                ));
            }
        }
    }

    /// Add Shout selector/bitness/padding constraints only (no CPU linkage).
    pub fn add_shout_instance_padding(&mut self, layout: &BusLayout, shout: &ShoutCols) {
        for j in 0..layout.chunk_size {
            let bus_has_lookup = layout.bus_cell(shout.has_lookup, j);
            let bus_val = layout.bus_cell(shout.primary_val(), j);

            // Ensure bus selector is boolean so gated-bit constraints imply true {0,1} bitness.
            self.add_boolean_constraint(CpuConstraintLabel::ShoutHasLookupBoolean, bus_has_lookup);

            // Padding: (1 - has_lookup) * val = 0
            self.constraints.push(CpuConstraint::new_zero_negated(
                CpuConstraintLabel::LookupValueZeroPadding,
                bus_has_lookup,
                bus_val,
            ));

            // Lookup key bits:
            // - Bitness: bit is 0 when inactive, boolean when active
            for col_id in shout.addr_bits.clone() {
                let bit = layout.bus_cell(col_id, j);
                self.add_gated_bit_constraint(CpuConstraintLabel::ShoutAddrBitBitness, bit, bus_has_lookup);
            }
        }
    }

    /// Add Shout addr-bit/value padding constraints without selector booleanity.
    pub fn add_shout_instance_padding_without_selector_bitness(&mut self, layout: &BusLayout, shout: &ShoutCols) {
        for j in 0..layout.chunk_size {
            let bus_has_lookup = layout.bus_cell(shout.has_lookup, j);
            let bus_val = layout.bus_cell(shout.primary_val(), j);

            // Padding: (1 - has_lookup) * val = 0
            self.constraints.push(CpuConstraint::new_zero_negated(
                CpuConstraintLabel::LookupValueZeroPadding,
                bus_has_lookup,
                bus_val,
            ));

            // Lookup key bits:
            // - Bitness: bit is 0 when inactive, boolean when active
            for col_id in shout.addr_bits.clone() {
                let bit = layout.bus_cell(col_id, j);
                self.add_gated_bit_constraint(CpuConstraintLabel::ShoutAddrBitBitness, bit, bus_has_lookup);
            }
        }
    }

    /// Add Shout selector/value padding only (no addr-bit constraints).
    pub fn add_shout_instance_padding_value_only(&mut self, layout: &BusLayout, shout: &ShoutCols) {
        for j in 0..layout.chunk_size {
            let bus_has_lookup = layout.bus_cell(shout.has_lookup, j);
            let bus_val = layout.bus_cell(shout.primary_val(), j);

            self.add_boolean_constraint(CpuConstraintLabel::ShoutHasLookupBoolean, bus_has_lookup);
            self.constraints.push(CpuConstraint::new_zero_negated(
                CpuConstraintLabel::LookupValueZeroPadding,
                bus_has_lookup,
                bus_val,
            ));
        }
    }

    /// Add Shout value padding only (no selector booleanity, no addr-bit constraints).
    pub fn add_shout_instance_value_padding_only(&mut self, layout: &BusLayout, shout: &ShoutCols) {
        for j in 0..layout.chunk_size {
            let bus_has_lookup = layout.bus_cell(shout.has_lookup, j);
            let bus_val = layout.bus_cell(shout.primary_val(), j);

            self.constraints.push(CpuConstraint::new_zero_negated(
                CpuConstraintLabel::LookupValueZeroPadding,
                bus_has_lookup,
                bus_val,
            ));
        }
    }

    /// Add unconditional addr-bit booleanity constraints for one shared-address Shout group.
    pub fn add_shout_instance_addr_bit_bitness(&mut self, layout: &BusLayout, shout: &ShoutCols) {
        for j in 0..layout.chunk_size {
            for col_id in shout.addr_bits.clone() {
                let bit = layout.bus_cell(col_id, j);
                self.add_boolean_constraint(CpuConstraintLabel::ShoutAddrBitBitness, bit);
            }
        }
    }

    /// Add an unconditional equality constraint: `left == right` (always).
    ///
    /// This is used for selector binding (is_load == has_read, etc.).
    /// Internally represented as: `1 * (left - right) = 0`
    pub fn add_equality_constraint(&mut self, label: CpuConstraintLabel, left_col: usize, right_col: usize) {
        self.constraints
            .push(CpuConstraint::new_eq(label, self.const_one_col, left_col, right_col));
    }

    /// Add unconditional constraints that mirror the **write** side of Twist across replicas.
    ///
    /// This is a pragmatic way to get multiple **read** ports against one logical memory without
    /// changing Twist: create `k` Twist instances with identical init/layout, bind each to its own
    /// CPU read columns, and then mirror the write stream across all instances so their states
    /// remain identical.
    ///
    /// The constraints enforce (for all `j`):
    /// - `has_write` equal across replicas
    /// - `wa_bits` equal across replicas
    /// - `wv` equal across replicas
    /// - `inc` equal across replicas
    ///
    /// Notes:
    /// - Read columns (`has_read`, `ra_bits`, `rv`) are intentionally **not** mirrored.
    /// - This helper assumes all replicas have identical `wa_bits` widths (same `d*ell`).
    pub fn add_twist_write_mirror_group(&mut self, layout: &BusLayout, twists: &[TwistCols]) {
        if twists.len() <= 1 {
            return;
        }
        let reference = &twists[0];
        let wa_len = reference
            .wa_bits
            .end
            .saturating_sub(reference.wa_bits.start);

        for other in twists.iter().skip(1) {
            let other_wa_len = other.wa_bits.end.saturating_sub(other.wa_bits.start);
            assert_eq!(
                other_wa_len, wa_len,
                "add_twist_write_mirror_group: wa_bits width mismatch (ref={wa_len}, other={other_wa_len})"
            );
            for j in 0..layout.chunk_size {
                self.add_equality_constraint(
                    CpuConstraintLabel::TwistWriteMirrorHasWrite,
                    layout.bus_cell(reference.has_write, j),
                    layout.bus_cell(other.has_write, j),
                );
                self.add_equality_constraint(
                    CpuConstraintLabel::TwistWriteMirrorWv,
                    layout.bus_cell(reference.wv, j),
                    layout.bus_cell(other.wv, j),
                );
                self.add_equality_constraint(
                    CpuConstraintLabel::TwistWriteMirrorInc,
                    layout.bus_cell(reference.inc, j),
                    layout.bus_cell(other.inc, j),
                );
                for (col_ref, col_other) in reference.wa_bits.clone().zip(other.wa_bits.clone()) {
                    self.add_equality_constraint(
                        CpuConstraintLabel::TwistWriteMirrorWaBits,
                        layout.bus_cell(col_ref, j),
                        layout.bus_cell(col_other, j),
                    );
                }
            }
        }
    }

    /// Get the accumulated constraints.
    pub fn constraints(&self) -> &[CpuConstraint<F>] {
        &self.constraints
    }

    /// Build the CCS structure from accumulated constraints.
    ///
    /// Each constraint `A(z) * B(z) = 0` becomes an R1CS constraint:
    /// - A matrix: the condition linear form
    /// - B matrix: the linear expression to gate
    /// - C matrix: all zeros
    ///
    /// The resulting CCS uses f(x1, x2, x3) = x1 * x2 - x3 (standard R1CS embedding).
    pub fn build(&self) -> Result<CcsStructure<F>, String>
    where
        F: PrimeCharacteristicRing + Copy + Eq + Send + Sync,
    {
        if self.constraints.is_empty() {
            return Err("no constraints added".to_string());
        }

        let n = self.n;
        let m = self.m;
        let num_constraints = self.constraints.len();

        // We need enough rows to place all generated constraints.
        if num_constraints > n {
            return Err(format!(
                "too many constraints ({}) for CCS with n={}",
                num_constraints, n
            ));
        }

        // Build A, B, C matrices for R1CS
        let mut a_data = vec![F::ZERO; n * m];
        let mut b_data = vec![F::ZERO; n * m];
        let c_data = vec![F::ZERO; n * m]; // C is all zeros for our constraints

        for (row, constraint) in self.constraints.iter().enumerate() {
            // A matrix: condition column(s)
            if constraint.negate_condition {
                // (1 - condition)
                a_data[row * m + self.const_one_col] = F::ONE;
                a_data[row * m + constraint.condition_col] = -F::ONE;
                for &col in &constraint.additional_condition_cols {
                    a_data[row * m + col] = -F::ONE;
                }
            } else {
                // Just condition
                a_data[row * m + constraint.condition_col] = F::ONE;
                for &col in &constraint.additional_condition_cols {
                    a_data[row * m + col] = F::ONE;
                }
            }

            // B matrix: Σ coeffᵢ · z[colᵢ]
            for &(col, coeff) in &constraint.b_terms {
                b_data[row * m + col] += coeff;
            }
        }

        // Create matrices
        let a = Mat::from_row_major(n, m, a_data);
        let b = Mat::from_row_major(n, m, b_data);
        let c = Mat::from_row_major(n, m, c_data);

        // Convert to CCS: f(x0, x1, x2) = x0 * x1 - x2
        let f = SparsePoly::new(
            3,
            vec![
                Term {
                    coeff: F::ONE,
                    exps: vec![1, 1, 0], // x0 * x1
                },
                Term {
                    coeff: -F::ONE,
                    exps: vec![0, 0, 1], // -x2
                },
            ],
        );
        CcsStructure::new(vec![a, b, c], f).map_err(|e| format!("failed to create CCS: {:?}", e))
    }

    /// Extend an existing CCS with bus binding constraints.
    ///
    /// This is the recommended way to add bus constraints to an existing CPU CCS.
    /// The function merges the constraint matrices while preserving the original
    /// CPU constraints.
    ///
    /// # Arguments
    /// * `base_ccs` - The original CPU CCS
    /// * `constraint_rows` - Which rows in the CCS to place the new constraints
    ///
    /// # Returns
    /// Extended CCS with bus binding constraints added.
    pub fn extend_ccs(&self, base_ccs: &CcsStructure<F>, constraint_start_row: usize) -> Result<CcsStructure<F>, String>
    where
        F: PrimeCharacteristicRing + Copy + Eq + Send + Sync,
    {
        if self.constraints.is_empty() {
            return Ok(base_ccs.clone());
        }

        let num_constraints = self.constraints.len();
        if constraint_start_row + num_constraints > base_ccs.n {
            return Err(format!(
                "constraint rows {} + {} exceed CCS n={}",
                constraint_start_row, num_constraints, base_ccs.n
            ));
        }

        // Ensure base CCS has at least 3 matrices (A, B, C from R1CS)
        if base_ccs.matrices.len() < 3 {
            return Err("base CCS must have at least 3 matrices (R1CS structure)".to_string());
        }

        let _m = base_ccs.m;
        let _n = base_ccs.n;

        // Clone base matrices (sparse CCS matrices).
        let mut matrices: Vec<CcsMatrix<F>> = base_ccs.matrices.clone();

        // Determine which matrix indices are A, B, C
        // For identity-first CCS: M_0 = I_n, M_1 = A, M_2 = B, M_3 = C
        // For non-identity-first: M_0 = A, M_1 = B, M_2 = C
        let (a_idx, b_idx, _c_idx) = if base_ccs.matrices.len() >= 4 && base_ccs.matrices[0].is_identity() {
            (1, 2, 3)
        } else {
            (0, 1, 2)
        };

        let to_triplets = |mat: &CcsMatrix<F>| -> Vec<(usize, usize, F)> {
            match mat {
                CcsMatrix::Identity { n } => {
                    let mut trips = Vec::with_capacity(*n);
                    for i in 0..*n {
                        trips.push((i, i, F::ONE));
                    }
                    trips
                }
                CcsMatrix::Csc(csc) => {
                    let mut trips = Vec::with_capacity(csc.vals.len());
                    for col in 0..csc.ncols {
                        let s0 = csc.col_ptr[col];
                        let e0 = csc.col_ptr[col + 1];
                        for k in s0..e0 {
                            trips.push((csc.row_idx[k], col, csc.vals[k]));
                        }
                    }
                    trips
                }
            }
        };

        // Extract existing A/B entries as triplets and append new constraint contributions.
        let mut a_trips = to_triplets(&matrices[a_idx]);
        let mut b_trips = to_triplets(&matrices[b_idx]);

        for (i, constraint) in self.constraints.iter().enumerate() {
            let row = constraint_start_row + i;

            // A matrix: condition.
            if constraint.negate_condition {
                // (1 - condition - Σ additional_conditions)
                a_trips.push((row, self.const_one_col, F::ONE));
                a_trips.push((row, constraint.condition_col, -F::ONE));
                for &col in &constraint.additional_condition_cols {
                    a_trips.push((row, col, -F::ONE));
                }
            } else {
                // (condition + Σ additional_conditions)
                a_trips.push((row, constraint.condition_col, F::ONE));
                for &col in &constraint.additional_condition_cols {
                    a_trips.push((row, col, F::ONE));
                }
            }

            // B matrix: Σ coeffᵢ · z[colᵢ]
            for &(col, coeff) in &constraint.b_terms {
                b_trips.push((row, col, coeff));
            }
        }

        // Rebuild A/B in CSC form, combining duplicates by summing coefficients.
        matrices[a_idx] = CcsMatrix::Csc(CscMat::from_triplets(a_trips, base_ccs.n, base_ccs.m));
        matrices[b_idx] = CcsMatrix::Csc(CscMat::from_triplets(b_trips, base_ccs.n, base_ccs.m));

        CcsStructure::new_sparse(matrices, base_ccs.f.clone()).map_err(|e| format!("failed to extend CCS: {:?}", e))
    }
}

/// Extend an existing **CPU CCS** with the canonical shared-bus binding + padding constraints.
///
/// This is the "no footguns" helper: it computes the shared-bus tail layout from the provided
/// instance metadata, builds the Jolt-derived constraints via `CpuConstraintBuilder`, and injects
/// them into the **last** rows of the base CCS (which must be reserved / unused).
///
/// ## Requirements
/// - The base CCS must be R1CS-embedded (A/B/C matrices, optionally identity-first).
/// - The base CCS must reserve enough trailing **all-zero** rows in A/B/C to fit the injected constraints.
/// - Only `chunk_size == 1` is supported (i.e., all instances must have `steps == 1`).
/// - `shout_cpu` must provide one binding per Shout lane, and `twist_cpu` must provide one binding per Twist lane.
///
/// ## Bus Ordering
/// This function assumes the caller passes instances in canonical bus order:
/// 1) all Shout instances (table_id-sorted order upstream),
/// 2) all Twist instances (mem_id-sorted order upstream).
pub fn extend_ccs_with_shared_cpu_bus_constraints<F: Field + PrimeCharacteristicRing + Copy + Eq + Send + Sync, Cmt>(
    base_ccs: &CcsStructure<F>,
    m_in: usize,
    const_one_col: usize,
    shout_cpu: &[ShoutCpuBinding],
    twist_cpu: &[TwistCpuBinding],
    lut_insts: &[LutInstance<Cmt, F>],
    mem_insts: &[MemInstance<Cmt, F>],
) -> Result<CcsStructure<F>, String> {
    let shout_cpu: Vec<Option<ShoutCpuBinding>> = shout_cpu.iter().cloned().map(Some).collect();
    extend_ccs_with_shared_cpu_bus_constraints_optional_shout(
        base_ccs,
        m_in,
        const_one_col,
        &shout_cpu,
        twist_cpu,
        lut_insts,
        mem_insts,
    )
}

/// Extend a CPU CCS with shared-bus constraints, allowing per-lane Shout linkage opt-out.
///
/// When a Shout lane binding is `None`, only canonical Shout padding/bitness constraints are
/// injected for that lane (no CPU selector/value/key linkage equalities).
pub fn extend_ccs_with_shared_cpu_bus_constraints_optional_shout<
    F: Field + PrimeCharacteristicRing + Copy + Eq + Send + Sync,
    Cmt,
>(
    base_ccs: &CcsStructure<F>,
    m_in: usize,
    const_one_col: usize,
    shout_cpu: &[Option<ShoutCpuBinding>],
    twist_cpu: &[TwistCpuBinding],
    lut_insts: &[LutInstance<Cmt, F>],
    mem_insts: &[MemInstance<Cmt, F>],
) -> Result<CcsStructure<F>, String> {
    let total_shout_lanes: usize = lut_insts.iter().map(|l| l.lanes.max(1)).sum();
    if shout_cpu.len() != total_shout_lanes {
        return Err(format!(
            "shout_cpu.len()={} != total_shout_lanes({total_shout_lanes})",
            shout_cpu.len(),
        ));
    }
    let total_twist_lanes: usize = mem_insts.iter().map(|m| m.lanes.max(1)).sum();
    if twist_cpu.len() != total_twist_lanes {
        return Err(format!(
            "twist_cpu.len()={} != total_twist_lanes({total_twist_lanes})",
            twist_cpu.len()
        ));
    }

    let mut chunk_size: usize = 1;
    if !lut_insts.is_empty() || !mem_insts.is_empty() {
        chunk_size = 0;
    }
    for (i, inst) in lut_insts.iter().enumerate() {
        if inst.steps == 0 {
            return Err(format!("lut_insts[{i}].steps must be >= 1"));
        }
        if chunk_size == 0 {
            chunk_size = inst.steps;
        } else if inst.steps != chunk_size {
            return Err(format!(
                "shared-bus requires a single chunk_size across instances; got lut_insts[{i}].steps={} but expected {chunk_size}",
                inst.steps
            ));
        }
    }
    for (i, inst) in mem_insts.iter().enumerate() {
        if inst.steps == 0 {
            return Err(format!("mem_insts[{i}].steps must be >= 1"));
        }
        if chunk_size == 0 {
            chunk_size = inst.steps;
        } else if inst.steps != chunk_size {
            return Err(format!(
                "shared-bus requires a single chunk_size across instances; got mem_insts[{i}].steps={} but expected {chunk_size}",
                inst.steps
            ));
        }
    }
    if chunk_size == 0 {
        chunk_size = 1;
    }

    let layout = build_bus_layout_for_instances_with_shout_shapes_and_twist_lanes(
        base_ccs.m,
        m_in,
        chunk_size,
        lut_insts.iter().map(|inst| ShoutInstanceShape {
            ell_addr: inst.d * inst.ell,
            lanes: inst.lanes.max(1),
            n_vals: 1usize,
            addr_group: rv32_trace_lookup_addr_group_for_table_shape(inst.table_id, inst.d * inst.ell).map(|v| v as u64),
            selector_group: rv32_trace_lookup_selector_group_for_table_id(inst.table_id).map(|v| v as u64),
        }),
        mem_insts
            .iter()
            .map(|inst| (inst.d * inst.ell, inst.lanes.max(1))),
    )?;

    if layout.bus_cols == 0 {
        return Ok(base_ccs.clone());
    }

    let mut builder = CpuConstraintBuilder::<F>::new(base_ccs.n, base_ccs.m, const_one_col);
    let mut addr_range_counts = std::collections::HashMap::<(usize, usize), usize>::new();
    for inst_cols in layout.shout_cols.iter() {
        for lane_cols in inst_cols.lanes.iter() {
            let key = (lane_cols.addr_bits.start, lane_cols.addr_bits.end);
            *addr_range_counts.entry(key).or_insert(0) += 1;
        }
    }
    let mut addr_range_bitness_added = std::collections::HashSet::<(usize, usize)>::new();
    let mut selector_bitness_added = std::collections::HashSet::<usize>::new();
    let mut shout_key_binding_added = std::collections::HashSet::<(bool, usize, usize, usize, usize)>::new();
    let mut shout_lane_idx = 0usize;
    for inst_cols in layout.shout_cols.iter() {
        for lane_cols in inst_cols.lanes.iter() {
            let key = (lane_cols.addr_bits.start, lane_cols.addr_bits.end);
            let shared_addr_group = addr_range_counts.get(&key).copied().unwrap_or(0) > 1;
            let cpu = shout_cpu
                .get(shout_lane_idx)
                .ok_or_else(|| format!("missing shout_cpu binding at lane_idx={shout_lane_idx}"))?;
            if let Some(cpu) = cpu {
                let mut dedup_cpu = cpu.clone();
                if let Some(addr_base) = dedup_cpu.addr {
                    let (is_bus_gate, gate_base) = if dedup_cpu.has_lookup == CPU_BUS_COL_DISABLED {
                        (true, lane_cols.has_lookup)
                    } else {
                        (false, dedup_cpu.has_lookup)
                    };
                    let key_sig = (
                        is_bus_gate,
                        gate_base,
                        addr_base,
                        lane_cols.addr_bits.start,
                        lane_cols.addr_bits.end,
                    );
                    if !shout_key_binding_added.insert(key_sig) {
                        dedup_cpu.addr = None;
                    }
                }
                builder.add_shout_instance_linkage_bound(&layout, lane_cols, &dedup_cpu);
            } else {
                // no linkage
            }
            let selector_first = selector_bitness_added.insert(lane_cols.has_lookup);
            if shared_addr_group {
                // Shared address bits across multiple table instances cannot use per-instance
                // `(1-has_lookup)*addr_bit=0` gating: inactive instances would overconstrain
                // active ones. Enforce has/value padding per-instance and addr-bit booleanity
                // once per shared range.
                if selector_first {
                    builder.add_shout_instance_padding_value_only(&layout, lane_cols);
                } else {
                    builder.add_shout_instance_value_padding_only(&layout, lane_cols);
                }
                if addr_range_bitness_added.insert(key) {
                    builder.add_shout_instance_addr_bit_bitness(&layout, lane_cols);
                }
            } else {
                if selector_first {
                    builder.add_shout_instance_padding(&layout, lane_cols);
                } else {
                    builder.add_shout_instance_padding_without_selector_bitness(&layout, lane_cols);
                }
            }
            shout_lane_idx += 1;
        }
    }
    debug_assert_eq!(shout_lane_idx, shout_cpu.len());
    let mut lane_idx = 0usize;
    for inst_cols in layout.twist_cols.iter() {
        for lane_cols in inst_cols.lanes.iter() {
            let cpu = twist_cpu
                .get(lane_idx)
                .ok_or_else(|| format!("missing twist_cpu binding at lane_idx={lane_idx}"))?;
            builder.add_twist_instance_bound(&layout, lane_cols, cpu);
            lane_idx += 1;
        }
    }

    let needed = builder.constraints().len();
    if needed == 0 {
        return Ok(base_ccs.clone());
    }
    if needed > base_ccs.n {
        return Err(format!(
            "not enough CCS rows to inject shared-bus constraints: need {needed}, have n={}",
            base_ccs.n
        ));
    }
    let start = base_ccs.n - needed;

    // Determine which matrix indices are A/B/C.
    let (a_idx, b_idx, c_idx) = if base_ccs.matrices.len() >= 4 && base_ccs.matrices[0].is_identity() {
        (1usize, 2usize, 3usize)
    } else if base_ccs.matrices.len() >= 3 {
        (0usize, 1usize, 2usize)
    } else {
        return Err("base CCS must have at least 3 matrices (R1CS A/B/C)".to_string());
    };

    // Refuse to overwrite any existing constraints: require trailing rows are empty in A/B/C.
    let first_nonzero_from_row = |m: &CcsMatrix<F>, start_row: usize| -> Option<usize> {
        match m {
            CcsMatrix::Identity { n } => (start_row < *n).then_some(start_row),
            CcsMatrix::Csc(csc) => csc
                .row_idx
                .iter()
                .copied()
                .filter(|&r| r >= start_row)
                .min(),
        }
    };

    let first_bad_row = [
        first_nonzero_from_row(&base_ccs.matrices[a_idx], start),
        first_nonzero_from_row(&base_ccs.matrices[b_idx], start),
        first_nonzero_from_row(&base_ccs.matrices[c_idx], start),
    ]
    .into_iter()
    .flatten()
    .min();

    if let Some(row) = first_bad_row {
        return Err(format!(
            "cannot inject shared-bus constraints: base CCS row {row} is not empty in A/B/C.\n\
             Fix: reserve the LAST {needed} rows of the base CPU R1CS as padding rows (all-zero in A/B/C)."
        ));
    }

    builder.extend_ccs(base_ccs, start)
}

/// Create padding constraints for all bus columns.
///
/// This is a convenience function that adds all necessary padding constraints
/// to ensure inactive bus fields are zero.
///
/// # Credits
/// Implements the "padding row constraints" recommended by the Jolt team:
/// - `(1 - has_read) * rv = 0`
/// - `(1 - has_write) * wv = 0`
/// - etc.
pub fn create_twist_padding_constraints<F: Field>(layout: &BusLayout, twist: &TwistCols) -> Vec<CpuConstraint<F>> {
    let mut constraints = Vec::new();
    for j in 0..layout.chunk_size {
        let bus_has_read = layout.bus_cell(twist.has_read, j);
        let bus_has_write = layout.bus_cell(twist.has_write, j);
        let bus_rv = layout.bus_cell(twist.rv, j);
        let bus_wv = layout.bus_cell(twist.wv, j);
        let bus_inc = layout.bus_cell(twist.inc, j);

        // (1 - has_read) * rv = 0
        constraints.push(CpuConstraint::new_zero_negated(
            CpuConstraintLabel::ReadValueZeroPadding,
            bus_has_read,
            bus_rv,
        ));

        // (1 - has_write) * wv = 0
        constraints.push(CpuConstraint::new_zero_negated(
            CpuConstraintLabel::WriteValueZeroPadding,
            bus_has_write,
            bus_wv,
        ));

        // (1 - has_write) * inc_at_write_addr = 0
        constraints.push(CpuConstraint::new_zero_negated(
            CpuConstraintLabel::IncrementZeroPadding,
            bus_has_write,
            bus_inc,
        ));

        // (1 - has_read) * ra_bits[i] = 0 for all i
        for col_id in twist.ra_bits.clone() {
            constraints.push(CpuConstraint::new_zero_negated(
                CpuConstraintLabel::ReadAddressBitsZeroPadding,
                bus_has_read,
                layout.bus_cell(col_id, j),
            ));
        }

        // (1 - has_write) * wa_bits[i] = 0 for all i
        for col_id in twist.wa_bits.clone() {
            constraints.push(CpuConstraint::new_zero_negated(
                CpuConstraintLabel::WriteAddressBitsZeroPadding,
                bus_has_write,
                layout.bus_cell(col_id, j),
            ));
        }
    }

    constraints
}

/// Create padding constraints for Shout (lookup) bus columns.
pub fn create_shout_padding_constraints<F: Field>(layout: &BusLayout, shout: &ShoutCols) -> Vec<CpuConstraint<F>> {
    let mut constraints = Vec::new();
    for j in 0..layout.chunk_size {
        let bus_has_lookup = layout.bus_cell(shout.has_lookup, j);
        let bus_val = layout.bus_cell(shout.primary_val(), j);

        // (1 - has_lookup) * val = 0
        constraints.push(CpuConstraint::new_zero_negated(
            CpuConstraintLabel::LookupValueZeroPadding,
            bus_has_lookup,
            bus_val,
        ));

        // (1 - has_lookup) * addr_bits[i] = 0 for all i
        for col_id in shout.addr_bits.clone() {
            constraints.push(CpuConstraint::new_zero_negated(
                CpuConstraintLabel::LookupAddressBitsZeroPadding,
                bus_has_lookup,
                layout.bus_cell(col_id, j),
            ));
        }
    }

    constraints
}

fn pack_addr_bits<F: Field>(addr_col: usize, bit_cols: Range<usize>, layout: &BusLayout, j: usize) -> Vec<(usize, F)> {
    let len = bit_cols.end.saturating_sub(bit_cols.start);
    let mut terms = Vec::with_capacity(1 + len);
    terms.push((addr_col, F::ONE));
    let mut weight = F::ONE;
    for col_id in bit_cols {
        terms.push((layout.bus_cell(col_id, j), -weight));
        weight = weight + weight; // *= 2
    }
    terms
}
